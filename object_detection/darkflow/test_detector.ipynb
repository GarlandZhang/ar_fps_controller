{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing cfg/yolov2-tiny-voc-hand.cfg\n",
      "Loading None ...\n",
      "Finished in 0.0s\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "WARNING:tensorflow:From C:\\Users\\GZhang\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "       |        | input                            | (?, 416, 416, 3)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1.0 usage\n",
      "Loading from E:/ar_fps/object_detection/ckpt\\yolov2-tiny-voc-hand-79440\n",
      "WARNING:tensorflow:From C:\\Users\\GZhang\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from E:/ar_fps/object_detection/ckpt\\yolov2-tiny-voc-hand-79440\n",
      "Finished in 8.422658443450928s\n",
      "\n",
      "Loading from E:/ar_fps/object_detection/ckpt\\yolov2-tiny-voc-hand-79440\n",
      "INFO:tensorflow:Restoring parameters from E:/ar_fps/object_detection/ckpt\\yolov2-tiny-voc-hand-79440\n"
     ]
    }
   ],
   "source": [
    "options2 = {\n",
    "    'gpu': 1.0,\n",
    "    'model': 'cfg/yolov2-tiny-voc-hand.cfg',\n",
    "    'load': 79440,\n",
    "    'threshold': 0.1,\n",
    "    'backup': 'E:/ar_fps/object_detection/ckpt',\n",
    "}\n",
    "tfnet2 = TFNet(options2)\n",
    "tfnet2.load_from_ckpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(xml_file):\n",
    "        boxes = []\n",
    "        classes = []\n",
    "        data = ET.parse(xml_file)\n",
    "        root = data.getroot()\n",
    "        objs = root.findall('object')\n",
    "        for obj in objs:\n",
    "            box = obj.find('bndbox')\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            box = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(box)\n",
    "            name = obj.find('name')\n",
    "            classes.append(name.text)\n",
    "        return boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: 480x640\n",
      "Num images found: 371 out of 433 => 0.8568129330254042\n",
      "Total time: 30.420039653778076\n",
      "Avg model time: 0.06747898273600167 or 14.819429094127049 fps\n",
      "Avg no write time: 0.06992426700459892 or 14.301186738707322 fps\n",
      "Avg time: 0.07025413314960295 or 14.23403798706826 fps\n"
     ]
    }
   ],
   "source": [
    "direc = os.path.join('new_data', 'egohands', 'train')\n",
    "# direc = 'E:/ar_fps/action_perception/frames'\n",
    "image_names = os.listdir(direc)\n",
    "# image_annots = os.listdir(direc + '_annotations')\n",
    "annot_direc = direc + '_annotations'\n",
    "\n",
    "\n",
    "\n",
    "imgs = []\n",
    "num_detected = 0\n",
    "\n",
    "orig_height = 416\n",
    "orig_width = 416\n",
    "\n",
    "model_time = 0\n",
    "total_time = 0\n",
    "total_no_write_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    if i == len(image_names):\n",
    "        break\n",
    "    img_name = image_names[i]\n",
    "#     img = cv2.imread(os.path.join(direc, img_name))\n",
    "#     img = cv2.resize(img, (640, 480))\n",
    "    start_time = time.time()\n",
    "#     ret, img = cap.read()\n",
    "    img = cv2.imread(os.path.join(direc, img_name))\n",
    "    height, width, _ = img.shape\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    model_start_time = time.time()\n",
    "    results = tfnet2.return_predict(img)\n",
    "    model_end_time = time.time()\n",
    "    pred_time = model_end_time - model_start_time\n",
    "    model_time += pred_time\n",
    "    if len(results) != 0:\n",
    "        num_detected += 1\n",
    "        for res in results:\n",
    "#             print(res)\n",
    "            top_left = (res['topleft']['x'], res['topleft']['y'])\n",
    "            bottom_right = (res['bottomright']['x'], res['bottomright']['y'])\n",
    "            label = res['label']\n",
    "            confidence = res['confidence']\n",
    "            top_left_conf = (res['topleft']['x'], res['topleft']['y'] + 30)\n",
    "            img = cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 7)\n",
    "            img = cv2.putText(img, label, top_left, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 1)\n",
    "            img = cv2.putText(img, str(confidence), top_left_conf, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 1)\n",
    "    # ground truth\n",
    "#     annot = os.path.join(annot_direc, img_name[:-3] + 'xml')\n",
    "#     if os.path.exists(annot):\n",
    "#         boxes, classes = read_xml(annot)\n",
    "#         for box in boxes:\n",
    "#             top_left = (box[0], box[1])\n",
    "#             bottom_right = (box[2], box[3])\n",
    "#             img = cv2.rectangle(img, top_left, bottom_right, (255, 0, 0), 7)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    imgs.append(img)\n",
    "    no_write_end_time = time.time()\n",
    "    pred_time = no_write_end_time - start_time\n",
    "    total_no_write_time += pred_time\n",
    "    cv2.imshow('img', img)\n",
    "#     cv2.imwrite('output/img{}.jpg'.format(i), img)\n",
    "    end_time = time.time()\n",
    "    pred_time = end_time - start_time\n",
    "    total_time += pred_time\n",
    "    i += 1\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "num_images = len(image_names)\n",
    "height, width, channels = img.shape\n",
    "print('Image resolution: {}x{}'.format(height, width))\n",
    "print('Num images found: {} out of {} => {}'.format(num_detected, i, num_detected / i))\n",
    "print('Total time: {}'.format(total_time))\n",
    "avg_model_time = model_time / i\n",
    "print('Avg model time: {} or {} fps'.format(avg_model_time, 1 / avg_model_time))\n",
    "avg_no_write_time = total_no_write_time / i\n",
    "print('Avg no write time: {} or {} fps'.format(avg_no_write_time, 1 / avg_no_write_time))\n",
    "avg_time = total_time / i\n",
    "print('Avg time: {} or {} fps'.format(avg_time, 1 / avg_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists('a'))\n",
    "# plotImages(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "b1f5ecc2-9402-4694-868a-a87391986ff5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
