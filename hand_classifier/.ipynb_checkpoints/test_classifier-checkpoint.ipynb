{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Softmax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_classifier('Deep-Learning/Transfer Learning CNN/mobilenet_set(4)_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "labels = get_class_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['point_foreward', 'point_up', 'curl']\n",
    "# test_label_ind = 2\n",
    "# # test_dir = 'images/train/{}'.format(labels[test_label_ind])\n",
    "# # test_dir = os.path.join('frames', 'curl')\n",
    "# preds = []\n",
    "# # test_dir = os.path.join('..', 'detect_classify_images', 'failed', 'point_foreward')\n",
    "# files = os.listdir(test_dir)\n",
    "# # print(files)\n",
    "# num_correct = 0\n",
    "# for f in files:\n",
    "#     img = cv2.imread(os.path.join(test_dir, f))\n",
    "#     img = cv2.resize(img, (HEIGHT, WIDTH))\n",
    "    \n",
    "#     batch = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "#     res = model.predict(batch)\n",
    "#     pred_ind = np.argmax(res[0])\n",
    "#     label = labels[pred_ind]\n",
    "#     preds.append(pred_ind)\n",
    "\n",
    "#     if pred_ind == test_label_ind:\n",
    "#         num_correct += 1\n",
    "    \n",
    "#     print('prediction: {} | actual: {}'.format(label, labels[test_label_ind]))\n",
    "# #     cv2.putText(img, label, (0, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,0), 1)\n",
    "# #     cv2.imshow('img', img)\n",
    "# #     while True:\n",
    "# #         k = cv2.waitKey(30) & 0xff\n",
    "# #         if k == ord('n'):\n",
    "# #             break\n",
    "# #         elif k == ord('q'):\n",
    "# #             files = []\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# print('Total correct: {} => accuracy of: {}'.format(num_correct, num_correct / len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor = preprocess_input(img_tensor)                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# live demo\n",
    "cap = cv2.VideoCapture(0)\n",
    "test_labels = ['curl_45_palm', 'point_foreward_45_palm', 'point_foreward_90_out', 'point_foreward_90_palm', 'point_up', 'point_up_thumb']\n",
    "test_labels = labels\n",
    "# test_labels = ['curl_45_palm']\n",
    "for j, class_label in enumerate(test_labels):\n",
    "    test_path = 'E:/ar_fps/data_collection/datasets_single_perspective/test/{}'.format(class_label)\n",
    "    # test_path = 'C:/Users/GZhang/Desktop/side-projects/ar_fps_sim/hand_classifier/images/train/point_up'\n",
    "    files = os.listdir(test_path)\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    height = HEIGHT\n",
    "    width = WIDTH\n",
    "    total_time = 0\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        if i == len(files):\n",
    "            break\n",
    "        else:\n",
    "            file_path = os.path.join(test_path, files[i])\n",
    "            frame = load_image(file_path)\n",
    "            res = model.predict(frame)\n",
    "            max_ind = np.argmax(res[0])\n",
    "            name = labels[max_ind]\n",
    "#             if 'curl' in class_label and 'curl' in name or 'point_foreward' in class_label and 'point_foreward' in name or 'point_up' in class_label and 'point_up' in name:\n",
    "            if max_ind == j:\n",
    "                correct += 1\n",
    "#             print(\"Actual: {} | Label: {} | Confidence: {}\".format(class_label, name, np.max(res[0])))\n",
    "    #     ret, frame = cap.read()\n",
    "    #     frame = cv2.imread(os.path.join(test_path, files[i]))\n",
    "    #     img = frame\n",
    "    #     crop = frame.copy()\n",
    "    #     crop = crop[200:200 + HEIGHT, 200:200 + WIDTH]\n",
    "    #     cv2.rectangle(frame, (200, 200), (200 + HEIGHT, 200 + WIDTH), (0, 255, 0), 3, 1)\n",
    "    #     img = cv2.resize(crop, (HEIGHT, WIDTH))\n",
    "    #     batch = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "    #     batch /= 255.    \n",
    "    #     res = model.predict(batch)\n",
    "    #     name = labels[np.argmax(res[0])]\n",
    "    #     print(name)\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time += end_time - start_time\n",
    "    #     cv2.putText(frame, \"{} | {}\".format(name, res), (40, 40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    #     print(\"{} | {}\".format(name, res))\n",
    "    #     frame = cv2.imread(os.path.join(test_path, file_path))\n",
    "    #     cv2.imshow('frame', frame)\n",
    "    #     cv2.imshow('cropped', crop)\n",
    "    #     cv2.imshow('img', img)\n",
    "\n",
    "        i += 1\n",
    "        k = cv2.waitKey(30) & 0xFF\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(class_label)\n",
    "    print('Total time: {}'.format(total_time))\n",
    "    print('Average time: {} or fps: {}'.format(total_time / len(files), len(files) / total_time))\n",
    "    print('Accuracy: {}'.format(correct / len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
